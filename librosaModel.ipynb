{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "librosaModel.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyNX9uKdlTiFQD5Gi1+x2gGQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/singhsa3/Emotions/blob/main/librosaModel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "16dOC0nljFI5"
      },
      "outputs": [],
      "source": [
        "# PyTorch libraries and modules\n",
        "import torch\n",
        "from torch.autograd import Variable\n",
        "from torch.nn import GroupNorm, Linear, ReLU, GELU, CrossEntropyLoss, Sequential, Conv2d, Conv1d, MaxPool2d, Module, Softmax, BatchNorm2d, Dropout,AvgPool2d\n",
        "from torch.optim import Adam, SGD\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch\n",
        "import torchvision\n",
        "from PIL import Image\n",
        "import torchvision.transforms as T\n",
        "from torchvision import datasets, transforms, models\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torch\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "pathG='/content/drive/MyDrive/Pract/data'\n",
        "cp = '/content/drive/MyDrive/Pretrained/wav2vec_small.pt'\n",
        "sample=\"/content/drive/MyDrive/Pract/data/voice_samples/1173_GM1001_1326493712.wav\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RfKTRJ9PjNjB",
        "outputId": "e5a50786-8604-4b04-ed7f-ac362af51708"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "DiMjz6Rhyd0L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "with open(pathG+\"/featuresdict.pickle\", \"rb\") as f:\n",
        "  features=pickle.load(f)\n",
        "with open(pathG+\"/filenameslist.pickle\", \"rb\") as f:\n",
        "  fnames=pickle.load(f)\n",
        "import pandas as pd\n",
        "df=pd.read_csv(pathG+\"/labels/Yared Alemu_fear.csv\")\n",
        "df = df[(df['name'].isin (features.keys()))].reset_index()\n",
        "df.head()"
      ],
      "metadata": {
        "id": "ZYaMFuEBkDds",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "6268fa33-35ef-49dc-f260-4273a382f62a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   index  Unnamed: 0    therapist                        name emotion_type  \\\n",
              "0      0        8265  Yared Alemu   6529_53113_3605013943.wav         fear   \n",
              "1      1        5540  Yared Alemu   8953_39117_2192499364.wav         fear   \n",
              "2      2        6675  Yared Alemu   1940_39117_1596672000.wav         fear   \n",
              "3      3        4640  Yared Alemu  53490_53113_1571011200.wav         fear   \n",
              "4      4        5525  Yared Alemu   8953_39117_4097508814.wav         fear   \n",
              "\n",
              "  rating  emotion  \n",
              "0   high        1  \n",
              "1    low        0  \n",
              "2    low        0  \n",
              "3    low        0  \n",
              "4    low        0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9c5ed246-54b9-467e-a8a3-06fce44dcd78\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>therapist</th>\n",
              "      <th>name</th>\n",
              "      <th>emotion_type</th>\n",
              "      <th>rating</th>\n",
              "      <th>emotion</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>8265</td>\n",
              "      <td>Yared Alemu</td>\n",
              "      <td>6529_53113_3605013943.wav</td>\n",
              "      <td>fear</td>\n",
              "      <td>high</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>5540</td>\n",
              "      <td>Yared Alemu</td>\n",
              "      <td>8953_39117_2192499364.wav</td>\n",
              "      <td>fear</td>\n",
              "      <td>low</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>6675</td>\n",
              "      <td>Yared Alemu</td>\n",
              "      <td>1940_39117_1596672000.wav</td>\n",
              "      <td>fear</td>\n",
              "      <td>low</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>4640</td>\n",
              "      <td>Yared Alemu</td>\n",
              "      <td>53490_53113_1571011200.wav</td>\n",
              "      <td>fear</td>\n",
              "      <td>low</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>5525</td>\n",
              "      <td>Yared Alemu</td>\n",
              "      <td>8953_39117_4097508814.wav</td>\n",
              "      <td>fear</td>\n",
              "      <td>low</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9c5ed246-54b9-467e-a8a3-06fce44dcd78')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9c5ed246-54b9-467e-a8a3-06fce44dcd78 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9c5ed246-54b9-467e-a8a3-06fce44dcd78');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['name2'] =df['name'].apply (lambda x: x.split(\".\")[0]+\".png\")"
      ],
      "metadata": {
        "id": "Crxr01It7ts1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train_x, val_x, train_y, val_y = train_test_split(df['name2'], df['emotion'], test_size = 0.3)"
      ],
      "metadata": {
        "id": "SBcKJSj65Oby"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "for src in list(train_x):\n",
        "  \n",
        "  src2=pathG+\"/greyimg/\"+src\n",
        "  lbl = df[df[\"name2\"]==src]['emotion'].values[0]\n",
        "  if lbl==0 :\n",
        "    dst= pathG+\"/temp/train/n/\"+src\n",
        "  else:\n",
        "    dst= pathG+\"/temp/train/y/\"+src\n",
        "  shutil.copyfile(src2, dst)\n",
        "\n",
        "for src in list(val_x):\n",
        "  lbl = df[df[\"name2\"]==src]['emotion'].values[0]\n",
        "  src2=pathG+\"/greyimg/\"+src\n",
        "  if lbl==0 :\n",
        "    dst= pathG+\"/temp/test/n/\"+src\n",
        "  else:\n",
        "    dst= pathG+\"/temp/test/y/\"+src\n",
        "  shutil.copyfile(src2, dst)\n",
        "  "
      ],
      "metadata": {
        "id": "Z78Tk09T-FQ5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "outputId": "c8b23c28-1835-4d3b-f365-e229ef65dda0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-b6e9369dd43c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mdst\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mpathG\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/temp/train/y/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m   \u001b[0mshutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopyfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msrc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/shutil.py\u001b[0m in \u001b[0;36mcopyfile\u001b[0;34m(src, dst, follow_symlinks)\u001b[0m\n\u001b[1;32m    119\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfsrc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m             \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfdst\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m                 \u001b[0mcopyfileobj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfsrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfdst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_data():\n",
        "    data_dir = pathG+\"/temp\"\n",
        "    print(data_dir)\n",
        "   \n",
        "    transform = transforms.Compose([\n",
        "        #transforms.RandomRotation(20),\n",
        "        #transforms.RandomResizedCrop(128),\n",
        "        #transforms.RandomHorizontalFlip(),\n",
        "        transforms.Grayscale(num_output_channels=1),\n",
        "        transforms.ToTensor()])\n",
        "\n",
        "    train_set = datasets.ImageFolder(data_dir + '/train', transform=transform)\n",
        "    test_set = datasets.ImageFolder(data_dir + '/test', transform=transform)\n",
        "\n",
        "    train = DataLoader(train_set, batch_size=8, shuffle=True)\n",
        "    test = DataLoader(test_set, batch_size=8, shuffle=True)\n",
        "\n",
        "    return train, test"
      ],
      "metadata": {
        "id": "b1rKD4_2CmAj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_imshow():\n",
        "    classes = (0, 1) # Defining the classes we have\n",
        "    dataiter = iter(train)\n",
        "    images, labels = dataiter.next()\n",
        "    fig, axes = plt.subplots(figsize=(10, 4), ncols=5)\n",
        "    for i in range(5):\n",
        "        ax = axes[i]\n",
        "        ax.imshow(images[i].permute(1, 2, 0)) \n",
        "        ax.title.set_text(' '.join('%5s' % classes[labels[i]]))\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "NLbWs7brD6Na"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train, test = get_data()\n",
        "\n",
        "#train_imshow()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wAcXLJ-AP8oP",
        "outputId": "f7e8416f-40a1-4397-9915-9e398d3252d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Pract/data/temp\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Net(nn.Module):   \n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        \n",
        "        self.cnn_layers = Sequential(\n",
        "            # Defining a 2D convolution layer\n",
        "            nn.Conv2d(1, 8, kernel_size=3, stride=1, padding=0), \n",
        "            nn.ReLU(),    \n",
        "            nn.AvgPool2d(kernel_size=2, stride=1), \n",
        "\n",
        "            nn.Conv2d(8, 16, kernel_size=2, stride=1, padding=0),\n",
        "            nn.ReLU(),                       \n",
        "            AvgPool2d(kernel_size=3, stride=1),\n",
        "\n",
        "            nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=0),\n",
        "            nn.ReLU(),\n",
        "            AvgPool2d(kernel_size=2, stride=1),         \n",
        "            \n",
        "        )\n",
        "         \n",
        "        self.linear_layers = Sequential(\n",
        "            nn.Linear(1479200,25088),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(25088, 2048),\n",
        "            nn.ReLU(),            \n",
        "            nn.Linear(2048, 2048),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(2048, 2),           \n",
        "        )\n",
        "\n",
        "    # Defining the forward pass    \n",
        "    def forward(self, x):\n",
        "        x = self.cnn_layers(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.linear_layers(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "isg2ajtLRfVI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net = Net()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.01, momentum=0.9)\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    model = net.cuda()\n",
        "    criterion = criterion.cuda()\n",
        "\n",
        "\n",
        "def train_net(n_epoch):\n",
        "    losses = []\n",
        "    for epoch in range(n_epoch):  # loop over the dataset multiple times\n",
        "        running_loss = 0.0\n",
        "        for i, data in enumerate(train, 0):\n",
        "            # get the inputs; data is a list of [inputs, labels]\n",
        "            inputs, labels = data\n",
        "\n",
        "            # zero the parameter gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # forward + backward + optimize\n",
        "            outputs = net(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # print statistics\n",
        "            losses.append(loss)\n",
        "            running_loss += loss.item()\n",
        "            if i % 100 == 99:  # print every 2000 mini-batches\n",
        "                print('[%d, %5d] loss: %.10f' %\n",
        "                      (epoch + 1, i + 1, running_loss / 2000))\n",
        "                running_loss = 0.0\n",
        "    plt.plot(losses, label='Training loss')\n",
        "    plt.show()\n",
        "    print('Finished Training')\n",
        "\n",
        "train_net(10)\n",
        "\n",
        "#PATH = './cat_dog_net.pth'\n",
        "# torch.save(net.state_dict(), PATH)\n",
        "\n",
        "# Loading the trained network\n",
        "# net.load_state_dict(torch.load(PATH))\n",
        "\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for data in test:\n",
        "        images, labels = data\n",
        "        outputs = net(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the %d test images: %d %%' % (len(test),\n",
        "    100 * correct / total))"
      ],
      "metadata": {
        "id": "REMxR5NnO1Ve"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "________________________________________"
      ],
      "metadata": {
        "id": "Rz2rwIludaBr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = pathG+\"/temp\"\n",
        "# Pass transforms in here, then run the next cell to see how the transforms look\n",
        "train_data = datasets.ImageFolder(data_dir + '/train', transform=train_transforms)\n",
        "test_data = datasets.ImageFolder(data_dir + '/test', transform=test_transforms)\n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(train_data, batch_size=64, shuffle=True)\n",
        "testloader = torch.utils.data.DataLoader(test_data, batch_size=64)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "bPaay66k72I8",
        "outputId": "fe53528d-7ae6-44cf-fb74-44c67366f335"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-16c4583c89fa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdata_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpathG\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/temp\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# Pass transforms in here, then run the next cell to see how the transforms look\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtrain_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImageFolder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/train'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_transforms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mtest_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImageFolder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/test'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_transforms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_transforms' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x=features[df.iloc[0][3]]\n",
        "x= np.pad(x, ((10,10),(10, 6500-x.shape[1])), 'constant')\n",
        "arr =np.expand_dims(x, axis=0)\n",
        "#print(arr.shape)\n",
        "for i,row in df.iterrows():\n",
        "  if i>0:\n",
        "    ft = features[row['name']]\n",
        "    ft= np.pad(ft, ((10,10),(10, 6500-ft.shape[1])), 'constant')\n",
        "    arr2 = np.expand_dims(ft, axis=0)\n",
        "    #print(arr2.shape)\n",
        "    arr = np.vstack((arr,arr2))\n",
        "labels=np.array(df.emotion)"
      ],
      "metadata": {
        "id": "h5VR9_vIobOI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "with open(pathG+\"/curfile.pickle\", \"wb\") as f:\n",
        "  pickle.dump((arr, labels),f)"
      ],
      "metadata": {
        "id": "KyEDslyx6DUQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Starting point"
      ],
      "metadata": {
        "id": "Ky15uqru6HU9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# PyTorch libraries and modules\n",
        "import torch\n",
        "from torch.autograd import Variable\n",
        "from torch.nn import GroupNorm, Linear, ReLU, GELU, CrossEntropyLoss, Sequential, Conv2d, Conv1d, MaxPool2d, Module, Softmax, BatchNorm2d, Dropout,AvgPool2d, Sigmoid\n",
        "from torch.optim import Adam, SGD\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "class Fp32GroupNorm(nn.GroupNorm):\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        super().__init__(*args, **kwargs)\n",
        "\n",
        "    def forward(self, input):\n",
        "        output = F.group_norm(\n",
        "            input.float(),\n",
        "            self.num_groups,\n",
        "            self.weight.float() if self.weight is not None else None,\n",
        "            self.bias.float() if self.bias is not None else None,\n",
        "            self.eps,\n",
        "        )\n",
        "        return output.type_as(input)\n"
      ],
      "metadata": {
        "id": "MN_IxsOuwtst"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "pathG='/content/drive/MyDrive/Pract/data'\n",
        "cp = '/content/drive/MyDrive/Pretrained/wav2vec_small.pt'\n",
        "sample=\"/content/drive/MyDrive/Pract/data/voice_samples/1173_GM1001_1326493712.wav\""
      ],
      "metadata": {
        "id": "KeAidBXINd9b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "with open(pathG+\"/curfile.pickle\", \"rb\") as f:\n",
        "  abc = pickle.load(f)\n",
        "arr=abc[0]\n",
        "labels=abc[1]"
      ],
      "metadata": {
        "id": "xGvEmAo467IL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train_x, val_x, train_y, val_y = train_test_split(arr, labels, test_size = 0.3)"
      ],
      "metadata": {
        "id": "anTlik-XxNjL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# converting training images into torch format\n",
        "train_x = train_x.reshape(train_x.shape[0], 1, train_x.shape[1], train_x.shape[2])\n",
        "train_x  = torch.from_numpy(train_x)\n",
        "\n",
        "# converting the target into torch format\n",
        "train_y = train_y.astype(int);\n",
        "train_y = torch.from_numpy(train_y)\n",
        "\n",
        "# shape of training data\n",
        "train_x.shape, train_y.shape\n",
        "# converting validation images into torch format\n",
        "val_x = val_x.reshape(val_x.shape[0], 1, val_x.shape[1], val_x.shape[2])\n",
        "val_x  = torch.from_numpy(val_x)\n",
        "\n",
        "# converting the target into torch format\n",
        "val_y = val_y.astype(int);\n",
        "val_y = torch.from_numpy(val_y)\n",
        "\n",
        "# shape of validation data\n",
        "val_x.shape, val_y.shape"
      ],
      "metadata": {
        "id": "W2Fqwi2YxgfU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader, TensorDataset"
      ],
      "metadata": {
        "id": "B10uqsUS2QDr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xbbbxbbxbxb"
      ],
      "metadata": {
        "id": "69IIy-kNzPZN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Net(nn.Module):   \n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        n= 808 # 240796 #117072 #6496 #14616 #\n",
        "        self.cnn_layers = Sequential(\n",
        "            # Defining a 2D convolution layer\n",
        "            nn.Conv2d(1, 4, kernel_size=2, stride=2, padding=0),\n",
        "            #BatchNorm2d(4),\n",
        "            ReLU(),\n",
        "            MaxPool2d(kernel_size=2, stride=2), \n",
        "            nn.Conv2d(4, 4, kernel_size=2, stride=2, padding=0),\n",
        "            #BatchNorm2d(4),\n",
        "            ReLU(),\n",
        "            MaxPool2d(kernel_size=2, stride=2),  \n",
        "            nn.Conv2d(4, 4, kernel_size=2, stride=2, padding=0),\n",
        "            #BatchNorm2d(4),\n",
        "            ReLU(),\n",
        "            MaxPool2d(kernel_size=2, stride=2),        \n",
        "       \n",
        "            \n",
        "        )\n",
        "         \n",
        "        self.linear_layers = Sequential(\n",
        "            Linear(n, int(n/2)),\n",
        "            ReLU(),\n",
        "            Linear(int(n/2), int(n/4)),\n",
        "            ReLU(),\n",
        "            Linear(int(n/4), 2),\n",
        "            #Sigmoid()\n",
        "        )\n",
        "\n",
        "    # Defining the forward pass    \n",
        "    def forward(self, x):\n",
        "        x = self.cnn_layers(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.linear_layers(x)\n",
        "        return x\n",
        "\n",
        "# defining the model\n",
        "model = Net()\n",
        "# defining the optimizer\n",
        "optimizer = Adam(model.parameters(), lr=0.1)\n",
        "# defining the loss function\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "# checking if GPU is available\n",
        "if torch.cuda.is_available():\n",
        "    model = model.cuda()\n",
        "    criterion = criterion.cuda()\n",
        "    \n",
        "#print(model)\n",
        "# Define the batch size and the number of epochs\n",
        "BATCH_SIZE = 10\n",
        "N_EPOCHS = 100\n",
        "torch.cuda.empty_cache()\n",
        "# Use torch.utils.data to create a DataLoader \n",
        "# that will take care of creating batches \n",
        "dataset = TensorDataset(train_x, train_y)\n",
        "dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "\n",
        "# Get the dataset size for printing (it is equal to N_SAMPLES)\n",
        "dataset_size = len(dataloader.dataset)\n",
        "# empty list to store training losses\n",
        "train_losses = [10000000,1000000,1000000,10000000,1000000]\n",
        "# empty list to store validation losses\n",
        "val_losses = []\n",
        "\n",
        "# Loop over epochs\n",
        "for epoch in range(N_EPOCHS):\n",
        "    mnl = np.mean(train_losses)\n",
        "    print(f\"Epoch {epoch + 1}\\n-------------------------------\")\n",
        "\n",
        "    # Loop over batches in an epoch using DataLoader\n",
        "    for id_batch, (x_batch, y_batch) in enumerate(dataloader):\n",
        "      if torch.cuda.is_available():\n",
        "        x_batch = x_batch.cuda()\n",
        "        y_batch = y_batch.cuda()\n",
        "        #x_val = val_x.cuda()\n",
        "        #y_val = val_y.cuda()\n",
        "\n",
        "        y_batch_pred = model(x_batch)\n",
        "        #output_val = model(x_val)\n",
        "\n",
        "        loss = criterion(y_batch_pred, y_batch)\n",
        "        #loss_val = criterion(output_val, y_val)\n",
        "        #train_losses.append(loss)\n",
        "        #val_losses.append(loss_val)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Every 100 batches, print the loss for this batch\n",
        "        # as well as the number of examples processed so far \n",
        "        if id_batch % 100 == 0:\n",
        "            loss, current = loss.item(), (id_batch + 1)* len(x_batch)\n",
        "            print(f\"loss: {loss:>7f}  [{current:>5d}/{dataset_size:>5d}]\")    \n",
        "    train_losses.pop()\n",
        "    train_losses.insert(0,loss.detach().cpu().numpy())\n",
        "    #if np.mean(train_losses)>mnl:\n",
        "      #break\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "# prediction for validation set\n",
        "predictions=[]\n",
        "dataset = TensorDataset(val_x, val_y)\n",
        "dataloader = DataLoader(dataset, batch_size=2, shuffle=True)\n",
        "for id_batch, (x_batch, y_batch) in enumerate(dataloader):\n",
        "      if torch.cuda.is_available():\n",
        "        x_batch = x_batch.cuda()\n",
        "        y_batch = y_batch.cuda()\n",
        "        x_val = val_x.cuda()\n",
        "        y_val = val_y.cuda()\n",
        "        output = model(x_batch)\n",
        "        softmax = torch.exp(output).cpu()\n",
        "        prob = list(softmax.detach().cpu().numpy())\n",
        "        prediction = np.argmax(prob, axis=1)\n",
        "        predictions = predictions+list(prediction)\n",
        "\n",
        "        \n",
        "\n",
        "# accuracy on validation set\n",
        "accuracy_score(val_y, np.array(predictions))"
      ],
      "metadata": {
        "id": "E0K3r2faEGAf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "# prediction for validation set\n",
        "predictions=[]\n",
        "dataset = TensorDataset(train_x, train_y)\n",
        "dataloader = DataLoader(dataset, batch_size=2, shuffle=True)\n",
        "for id_batch, (x_batch, y_batch) in enumerate(dataloader):\n",
        "      if torch.cuda.is_available():\n",
        "        x_batch = x_batch.cuda()\n",
        "        y_batch = y_batch.cuda()\n",
        "        x_val = train_x.cuda()\n",
        "        y_val = train_y.cuda()\n",
        "        output = model(x_batch)\n",
        "        softmax = torch.exp(output).cpu()\n",
        "        prob = list(softmax.detach().cpu().numpy())\n",
        "        prediction = np.argmax(prob, axis=1)\n",
        "        predictions = predictions+list(prediction)\n",
        "\n",
        "        \n",
        "\n",
        "# accuracy on validation set\n",
        "accuracy_score(train_y, np.array(predictions))"
      ],
      "metadata": {
        "id": "KmzS2rRB_W32"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " # Defining another 2D convolution layer\n",
        "            Conv2d(2, 4, kernel_size=2, stride=1, padding=0),\n",
        "            #BatchNorm2d(16),\n",
        "            ReLU(),\n",
        "            AvgPool2d(kernel_size=4, stride=1),\n",
        "            # Defining another 2D convolution layer\n",
        "            Conv2d(4, 4, kernel_size=2, stride=1, padding=0),\n",
        "            #BatchNorm2d(64),\n",
        "            ReLU(),\n",
        "            MaxPool2d(kernel_size=4, stride=1),"
      ],
      "metadata": {
        "id": "ZXTS7o-w25ri"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "dmFNwp1SI7xU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model, 'model.bin')"
      ],
      "metadata": {
        "id": "5nt7Xn-z0j35"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = torch.load('model.bin')\n",
        "model.eval()"
      ],
      "metadata": {
        "id": "xgK7B4xg0vNY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "torch.cuda.empty_cache()\n",
        "!nvidia-smi\n",
        "a = torch.cuda.memory_allocated(0)\n",
        "c = torch.cuda.memory_reserved(0)\n",
        "print(a,c)"
      ],
      "metadata": {
        "id": "yXCniVom8nEI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "M3MFC8yELtJQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "     \n",
        "    \n",
        "  "
      ],
      "metadata": {
        "id": "ZaQxRAfVmJ9S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "     \n",
        "    \n",
        "  "
      ],
      "metadata": {
        "id": "iFPjEFmYrUl_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}