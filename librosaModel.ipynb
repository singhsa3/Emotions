{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "librosaModel.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyMYHdDO69X3BRPiNLtUa6kf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/singhsa3/Emotions/blob/main/librosaModel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "16dOC0nljFI5"
      },
      "outputs": [],
      "source": [
        "# PyTorch libraries and modules\n",
        "import torch\n",
        "from torch.autograd import Variable\n",
        "from torch.nn import GroupNorm, Linear, ReLU, GELU, CrossEntropyLoss, Sequential, Conv2d, Conv1d, MaxPool2d, Module, Softmax, BatchNorm2d, Dropout,AvgPool2d\n",
        "from torch.optim import Adam, SGD\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "pathG='/content/drive/MyDrive/Pract/data'\n",
        "cp = '/content/drive/MyDrive/Pretrained/wav2vec_small.pt'\n",
        "sample=\"/content/drive/MyDrive/Pract/data/voice_samples/1173_GM1001_1326493712.wav\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RfKTRJ9PjNjB",
        "outputId": "58db5af0-4184-4a1e-8849-e783d15f79c9"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "with open(pathG+\"/featuresdict.pickle\", \"rb\") as f:\n",
        "  features=pickle.load(f)\n",
        "with open(pathG+\"/filenameslist.pickle\", \"rb\") as f:\n",
        "  fnames=pickle.load(f)\n",
        "import pandas as pd\n",
        "df=pd.read_csv(pathG+\"/labels/Yared Alemu_fear.csv\")\n",
        "df = df[(df['name'].isin (features.keys()))].reset_index()\n",
        "df.head()"
      ],
      "metadata": {
        "id": "ZYaMFuEBkDds",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "f7ca38c2-9f3c-4ede-f2d5-644d6b026d89"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   index  Unnamed: 0    therapist                        name emotion_type  \\\n",
              "0      0        8265  Yared Alemu   6529_53113_3605013943.wav         fear   \n",
              "1      1        5540  Yared Alemu   8953_39117_2192499364.wav         fear   \n",
              "2      2        6675  Yared Alemu   1940_39117_1596672000.wav         fear   \n",
              "3      3        4640  Yared Alemu  53490_53113_1571011200.wav         fear   \n",
              "4      4        5525  Yared Alemu   8953_39117_4097508814.wav         fear   \n",
              "\n",
              "  rating  emotion  \n",
              "0   high        1  \n",
              "1    low        0  \n",
              "2    low        0  \n",
              "3    low        0  \n",
              "4    low        0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ebde36be-6d2d-482e-9bb4-7fde7a5ea6d2\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>therapist</th>\n",
              "      <th>name</th>\n",
              "      <th>emotion_type</th>\n",
              "      <th>rating</th>\n",
              "      <th>emotion</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>8265</td>\n",
              "      <td>Yared Alemu</td>\n",
              "      <td>6529_53113_3605013943.wav</td>\n",
              "      <td>fear</td>\n",
              "      <td>high</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>5540</td>\n",
              "      <td>Yared Alemu</td>\n",
              "      <td>8953_39117_2192499364.wav</td>\n",
              "      <td>fear</td>\n",
              "      <td>low</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>6675</td>\n",
              "      <td>Yared Alemu</td>\n",
              "      <td>1940_39117_1596672000.wav</td>\n",
              "      <td>fear</td>\n",
              "      <td>low</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>4640</td>\n",
              "      <td>Yared Alemu</td>\n",
              "      <td>53490_53113_1571011200.wav</td>\n",
              "      <td>fear</td>\n",
              "      <td>low</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>5525</td>\n",
              "      <td>Yared Alemu</td>\n",
              "      <td>8953_39117_4097508814.wav</td>\n",
              "      <td>fear</td>\n",
              "      <td>low</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ebde36be-6d2d-482e-9bb4-7fde7a5ea6d2')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ebde36be-6d2d-482e-9bb4-7fde7a5ea6d2 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ebde36be-6d2d-482e-9bb4-7fde7a5ea6d2');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x=features[df.iloc[0][3]]\n",
        "x= np.pad(x, ((10,10),(10, 6500-x.shape[1])), 'constant')\n",
        "arr =np.expand_dims(x, axis=0)\n",
        "#print(arr.shape)\n",
        "for i,row in df.iterrows():\n",
        "  if i>0:\n",
        "    ft = features[row['name']]\n",
        "    ft= np.pad(ft, ((10,10),(10, 6500-ft.shape[1])), 'constant')\n",
        "    arr2 = np.expand_dims(ft, axis=0)\n",
        "    #print(arr2.shape)\n",
        "    arr = np.vstack((arr,arr2))\n",
        "labels=np.array(df.emotion)"
      ],
      "metadata": {
        "id": "h5VR9_vIobOI"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "with open(pathG+\"/curfile.pickle\", \"wb\") as f:\n",
        "  pickle.dump((arr, labels),f)"
      ],
      "metadata": {
        "id": "KyEDslyx6DUQ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Ky15uqru6HU9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# PyTorch libraries and modules\n",
        "import torch\n",
        "from torch.autograd import Variable\n",
        "from torch.nn import GroupNorm, Linear, ReLU, GELU, CrossEntropyLoss, Sequential, Conv2d, Conv1d, MaxPool2d, Module, Softmax, BatchNorm2d, Dropout,AvgPool2d\n",
        "from torch.optim import Adam, SGD\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "class Fp32GroupNorm(nn.GroupNorm):\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        super().__init__(*args, **kwargs)\n",
        "\n",
        "    def forward(self, input):\n",
        "        output = F.group_norm(\n",
        "            input.float(),\n",
        "            self.num_groups,\n",
        "            self.weight.float() if self.weight is not None else None,\n",
        "            self.bias.float() if self.bias is not None else None,\n",
        "            self.eps,\n",
        "        )\n",
        "        return output.type_as(input)\n"
      ],
      "metadata": {
        "id": "MN_IxsOuwtst"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "pathG='/content/drive/MyDrive/Pract/data'\n",
        "cp = '/content/drive/MyDrive/Pretrained/wav2vec_small.pt'\n",
        "sample=\"/content/drive/MyDrive/Pract/data/voice_samples/1173_GM1001_1326493712.wav\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KeAidBXINd9b",
        "outputId": "0a1f3d33-f11d-4cf9-f7a3-35e1eb1adf95"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "with open(pathG+\"/curfile.pickle\", \"rb\") as f:\n",
        "  abc = pickle.load(f)\n",
        "arr=abc[0]\n",
        "labels=abc[1]"
      ],
      "metadata": {
        "id": "xGvEmAo467IL"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train_x, val_x, train_y, val_y = train_test_split(arr, labels, test_size = 0.3)"
      ],
      "metadata": {
        "id": "anTlik-XxNjL"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# converting training images into torch format\n",
        "train_x = train_x.reshape(train_x.shape[0], 1, train_x.shape[1], train_x.shape[2])\n",
        "train_x  = torch.from_numpy(train_x)\n",
        "\n",
        "# converting the target into torch format\n",
        "train_y = train_y.astype(int);\n",
        "train_y = torch.from_numpy(train_y)\n",
        "\n",
        "# shape of training data\n",
        "train_x.shape, train_y.shape\n",
        "# converting validation images into torch format\n",
        "val_x = val_x.reshape(val_x.shape[0], 1, val_x.shape[1], val_x.shape[2])\n",
        "val_x  = torch.from_numpy(val_x)\n",
        "\n",
        "# converting the target into torch format\n",
        "val_y = val_y.astype(int);\n",
        "val_y = torch.from_numpy(val_y)\n",
        "\n",
        "# shape of validation data\n",
        "val_x.shape, val_y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W2Fqwi2YxgfU",
        "outputId": "8e3ebba3-ace8-477d-ba96-19b08efe16a0"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([127, 1, 148, 6510]), torch.Size([127]))"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "torch.cuda.empty_cache()\n",
        "!nvidia-smi\n",
        "a = torch.cuda.memory_allocated(0)\n",
        "c = torch.cuda.memory_reserved(0)\n",
        "print(a,c)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vuxXjoYz2a2l",
        "outputId": "4f67c3eb-089f-4a03-dfee-2f358de3de10"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sun Jun  5 01:33:13 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   46C    P0    27W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n",
            "0 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader, TensorDataset"
      ],
      "metadata": {
        "id": "B10uqsUS2QDr"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Net(Module):   \n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "\n",
        "        self.cnn_layers = Sequential(\n",
        "            # Defining a 2D convolution layer\n",
        "            Conv2d(1, 4, kernel_size=2, stride=1, padding=0),\n",
        "            BatchNorm2d(4),\n",
        "            ReLU(inplace=True),\n",
        "            AvgPool2d(kernel_size=4, stride=1),\n",
        "            # Defining another 2D convolution layer\n",
        "            Conv2d(4, 16, kernel_size=2, stride=1, padding=0),\n",
        "            BatchNorm2d(16),\n",
        "            ReLU(inplace=True),\n",
        "            AvgPool2d(kernel_size=4, stride=1),\n",
        "            # Defining another 2D convolution layer\n",
        "            Conv2d(16, 64, kernel_size=2, stride=1, padding=0),\n",
        "            BatchNorm2d(64),\n",
        "            ReLU(inplace=True),\n",
        "            AvgPool2d(kernel_size=4, stride=1),\n",
        "            \n",
        "        )\n",
        "\n",
        "        self.linear_layers = Sequential(\n",
        "            Linear(56558592, 2)\n",
        "        )\n",
        "\n",
        "    # Defining the forward pass    \n",
        "    def forward(self, x):\n",
        "        x = self.cnn_layers(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.linear_layers(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "69IIy-kNzPZN"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# defining the model\n",
        "model = Net()\n",
        "# defining the optimizer\n",
        "optimizer = Adam(model.parameters(), lr=0.07)\n",
        "# defining the loss function\n",
        "criterion = CrossEntropyLoss()\n",
        "# checking if GPU is available\n",
        "if torch.cuda.is_available():\n",
        "    model = model.cuda()\n",
        "    criterion = criterion.cuda()\n",
        "    \n",
        "#print(model)\n",
        "# Define the batch size and the number of epochs\n",
        "BATCH_SIZE = 5\n",
        "N_EPOCHS = 50\n",
        "torch.cuda.empty_cache()\n",
        "# Use torch.utils.data to create a DataLoader \n",
        "# that will take care of creating batches \n",
        "dataset = TensorDataset(train_x, train_y)\n",
        "dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "\n",
        "# Get the dataset size for printing (it is equal to N_SAMPLES)\n",
        "dataset_size = len(dataloader.dataset)\n",
        "# empty list to store training losses\n",
        "train_losses = [100,100,100,100,100]\n",
        "# empty list to store validation losses\n",
        "val_losses = []\n",
        "\n",
        "# Loop over epochs\n",
        "for epoch in range(N_EPOCHS):\n",
        "    mnl = np.mean(train_losses)\n",
        "    print(f\"Epoch {epoch + 1}\\n-------------------------------\")\n",
        "\n",
        "    # Loop over batches in an epoch using DataLoader\n",
        "    for id_batch, (x_batch, y_batch) in enumerate(dataloader):\n",
        "      if torch.cuda.is_available():\n",
        "        x_batch = x_batch.cuda()\n",
        "        y_batch = y_batch.cuda()\n",
        "        #x_val = val_x.cuda()\n",
        "        #y_val = val_y.cuda()\n",
        "\n",
        "        y_batch_pred = model(x_batch)\n",
        "        #output_val = model(x_val)\n",
        "\n",
        "        loss = criterion(y_batch_pred, y_batch)\n",
        "        #loss_val = criterion(output_val, y_val)\n",
        "        #train_losses.append(loss)\n",
        "        #val_losses.append(loss_val)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Every 100 batches, print the loss for this batch\n",
        "        # as well as the number of examples processed so far \n",
        "        if id_batch % 100 == 0:\n",
        "            loss, current = loss.item(), (id_batch + 1)* len(x_batch)\n",
        "            print(f\"loss: {loss:>7f}  [{current:>5d}/{dataset_size:>5d}]\")    \n",
        "    train_losses.pop()\n",
        "    train_losses.insert(0,loss.detach().cpu().numpy())\n",
        "    #if np.mean(train_losses)>mnl*1.10:\n",
        "      #break\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E0K3r2faEGAf",
        "outputId": "737125be-5a04-46d9-980f-5ba6227894fe"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "-------------------------------\n",
            "loss: 0.695104  [    5/  295]\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "loss: 8.908305  [    5/  295]\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "loss: 0.404806  [    5/  295]\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "loss: 0.520656  [    5/  295]\n",
            "Epoch 5\n",
            "-------------------------------\n",
            "loss: 0.550291  [    5/  295]\n",
            "Epoch 6\n",
            "-------------------------------\n",
            "loss: 0.660351  [    5/  295]\n",
            "Epoch 7\n",
            "-------------------------------\n",
            "loss: 2.992746  [    5/  295]\n",
            "Epoch 8\n",
            "-------------------------------\n",
            "loss: 0.737954  [    5/  295]\n",
            "Epoch 9\n",
            "-------------------------------\n",
            "loss: 0.624739  [    5/  295]\n",
            "Epoch 10\n",
            "-------------------------------\n",
            "loss: 0.680556  [    5/  295]\n",
            "Epoch 11\n",
            "-------------------------------\n",
            "loss: 0.701996  [    5/  295]\n",
            "Epoch 12\n",
            "-------------------------------\n",
            "loss: 0.695752  [    5/  295]\n",
            "Epoch 13\n",
            "-------------------------------\n",
            "loss: 0.560792  [    5/  295]\n",
            "Epoch 14\n",
            "-------------------------------\n",
            "loss: 0.716229  [    5/  295]\n",
            "Epoch 15\n",
            "-------------------------------\n",
            "loss: 0.472639  [    5/  295]\n",
            "Epoch 16\n",
            "-------------------------------\n",
            "loss: 0.656659  [    5/  295]\n",
            "Epoch 17\n",
            "-------------------------------\n",
            "loss: 0.344878  [    5/  295]\n",
            "Epoch 18\n",
            "-------------------------------\n",
            "loss: 0.719359  [    5/  295]\n",
            "Epoch 19\n",
            "-------------------------------\n",
            "loss: 0.695778  [    5/  295]\n",
            "Epoch 20\n",
            "-------------------------------\n",
            "loss: 0.655412  [    5/  295]\n",
            "Epoch 21\n",
            "-------------------------------\n",
            "loss: 0.190547  [    5/  295]\n",
            "Epoch 22\n",
            "-------------------------------\n",
            "loss: 0.659395  [    5/  295]\n",
            "Epoch 23\n",
            "-------------------------------\n",
            "loss: 0.463218  [    5/  295]\n",
            "Epoch 24\n",
            "-------------------------------\n",
            "loss: 0.485058  [    5/  295]\n",
            "Epoch 25\n",
            "-------------------------------\n",
            "loss: 0.275564  [    5/  295]\n",
            "Epoch 26\n",
            "-------------------------------\n",
            "loss: 0.015826  [    5/  295]\n",
            "Epoch 27\n",
            "-------------------------------\n",
            "loss: 0.186421  [    5/  295]\n",
            "Epoch 28\n",
            "-------------------------------\n",
            "loss: 0.011724  [    5/  295]\n",
            "Epoch 29\n",
            "-------------------------------\n",
            "loss: 0.002249  [    5/  295]\n",
            "Epoch 30\n",
            "-------------------------------\n",
            "loss: 0.044802  [    5/  295]\n",
            "Epoch 31\n",
            "-------------------------------\n",
            "loss: 0.010499  [    5/  295]\n",
            "Epoch 32\n",
            "-------------------------------\n",
            "loss: 0.004725  [    5/  295]\n",
            "Epoch 33\n",
            "-------------------------------\n",
            "loss: 0.017115  [    5/  295]\n",
            "Epoch 34\n",
            "-------------------------------\n",
            "loss: 0.145220  [    5/  295]\n",
            "Epoch 35\n",
            "-------------------------------\n",
            "loss: 0.037983  [    5/  295]\n",
            "Epoch 36\n",
            "-------------------------------\n",
            "loss: 0.002411  [    5/  295]\n",
            "Epoch 37\n",
            "-------------------------------\n",
            "loss: 0.049891  [    5/  295]\n",
            "Epoch 38\n",
            "-------------------------------\n",
            "loss: 0.000418  [    5/  295]\n",
            "Epoch 39\n",
            "-------------------------------\n",
            "loss: 0.000002  [    5/  295]\n",
            "Epoch 40\n",
            "-------------------------------\n",
            "loss: 0.015553  [    5/  295]\n",
            "Epoch 41\n",
            "-------------------------------\n",
            "loss: 0.004039  [    5/  295]\n",
            "Epoch 42\n",
            "-------------------------------\n",
            "loss: 0.000937  [    5/  295]\n",
            "Epoch 43\n",
            "-------------------------------\n",
            "loss: 0.001025  [    5/  295]\n",
            "Epoch 44\n",
            "-------------------------------\n",
            "loss: 0.028025  [    5/  295]\n",
            "Epoch 45\n",
            "-------------------------------\n",
            "loss: 0.107821  [    5/  295]\n",
            "Epoch 46\n",
            "-------------------------------\n",
            "loss: 0.001610  [    5/  295]\n",
            "Epoch 47\n",
            "-------------------------------\n",
            "loss: 0.013185  [    5/  295]\n",
            "Epoch 48\n",
            "-------------------------------\n",
            "loss: 0.000249  [    5/  295]\n",
            "Epoch 49\n",
            "-------------------------------\n",
            "loss: 0.525238  [    5/  295]\n",
            "Epoch 50\n",
            "-------------------------------\n",
            "loss: 0.622788  [    5/  295]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model, 'model.bin')"
      ],
      "metadata": {
        "id": "5nt7Xn-z0j35"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = torch.load('model.bin')\n",
        "model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xgK7B4xg0vNY",
        "outputId": "a77960b8-107f-4702-968c-675b43ac1bbf"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Net(\n",
              "  (cnn_layers): Sequential(\n",
              "    (0): Conv2d(1, 4, kernel_size=(2, 2), stride=(1, 1))\n",
              "    (1): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU(inplace=True)\n",
              "    (3): AvgPool2d(kernel_size=4, stride=1, padding=0)\n",
              "    (4): Conv2d(4, 16, kernel_size=(2, 2), stride=(1, 1))\n",
              "    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (6): ReLU(inplace=True)\n",
              "    (7): AvgPool2d(kernel_size=4, stride=1, padding=0)\n",
              "    (8): Conv2d(16, 64, kernel_size=(2, 2), stride=(1, 1))\n",
              "    (9): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (10): ReLU(inplace=True)\n",
              "    (11): AvgPool2d(kernel_size=4, stride=1, padding=0)\n",
              "  )\n",
              "  (linear_layers): Sequential(\n",
              "    (0): Linear(in_features=56558592, out_features=2, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "torch.cuda.empty_cache()\n",
        "!nvidia-smi\n",
        "a = torch.cuda.memory_allocated(0)\n",
        "c = torch.cuda.memory_reserved(0)\n",
        "print(a,c)"
      ],
      "metadata": {
        "id": "yXCniVom8nEI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c46573a-f3fe-4197-9c12-b99b42bcf2dc"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sun Jun  5 02:17:33 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   69C    P0    46W / 250W |   3361MiB / 16280MiB |      1%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n",
            "2283282944 2514485248\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "# prediction for validation set\n",
        "predictions=[]\n",
        "dataset = TensorDataset(val_x, val_y)\n",
        "dataloader = DataLoader(dataset, batch_size=2, shuffle=True)\n",
        "for id_batch, (x_batch, y_batch) in enumerate(dataloader):\n",
        "      if torch.cuda.is_available():\n",
        "        x_batch = x_batch.cuda()\n",
        "        y_batch = y_batch.cuda()\n",
        "        x_val = val_x.cuda()\n",
        "        y_val = val_y.cuda()\n",
        "        output = model(x_batch)\n",
        "        softmax = torch.exp(output).cpu()\n",
        "        prob = list(softmax.detach().cpu().numpy())\n",
        "        prediction = np.argmax(prob, axis=1)\n",
        "        predictions = predictions+list(prediction)\n",
        "\n",
        "        \n",
        "\n",
        "# accuracy on validation set\n",
        "accuracy_score(val_y, np.array(predictions))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M3MFC8yELtJQ",
        "outputId": "8cc89cce-1097-461e-a831-afd3e4ebf85c"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.47244094488188976"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "     \n",
        "    \n",
        "  "
      ],
      "metadata": {
        "id": "ZaQxRAfVmJ9S"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "     \n",
        "    \n",
        "  "
      ],
      "metadata": {
        "id": "iFPjEFmYrUl_"
      },
      "execution_count": 13,
      "outputs": []
    }
  ]
}